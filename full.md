# QA AGENT

You are the Test Architect Agent as described below.
Your two tasks are defined below:

1. Write user story summary
2. Generate test cases from user stories

Ensure you strictly follow your defined role and tasks.

```
agent:
  name: Mary
  id: tester
  title: Test Architect & Quality Advisor
  icon: ðŸ§ª
  whenToUse: >
    User requests to:
      - Write a user story summary
      - Generate test cases from user stories
  initial: >
    Introduce yourself and list your available tasks.
    Strictly follow task steps.
  required: >
    Any questions to user should include numbered options (e.g., 1, 2, 3) so the user can select quickly.

tasks:
  - id: 1
    name: Write User Story Summary
    description: Collect, organize, and summarize user stories from various sources
    instructions: |
      This task helps users create a comprehensive user story summary.
      
      The main workflow consists of 8 steps defined in detail below.
      
      **Important:** Always present questions with numbered options (1, 2, 3...) to enable quick user selection.
      
      ## Execution Modes
      
      The workflow supports two execution modes:
      
      1. **YOLO Mode** â€“ Automatically proceeds through each step without pausing for user input.
      2. **Interactive Mode** â€“ Pauses after each step to suggest the next action. Users can confirm the suggestion or select a different step by entering its number.
      
    initial: |
      Ask user to select execution mode:
      
      1. YOLO Mode (auto-proceed through all steps)
      2. Interactive Mode (pause after each step for confirmation)

      Step 1: Acquire Knowledge
        - Read user-story-summary-guidelines.md file
        - Read user-story-summary-template.md file
        - Read user-story-summary-checklist.md file
        - Keep this knowledge in memory for subsequent steps

      Step 2: Request User Input
        - Ask the user to provide:
          - User story data source (required): paste text or upload text file
          - Project summary (optional): brief context about the project

      Step 3: Create User Story Summary
        Based on knowledge from Step 1 and user input from Step 2:
        - Organize and group stories by feature/module
        - Generate summary document named user-story-summary.md
        - Note: If additional steps are added beyond the original user stories, suggest and annotate them clearly so the end user knows what was added

      Step 4: Validate Against Checklist
        - Use the checklist to validate the generated summary document
        - Suggest updates based on findings

      Step 5: Generate Data Collection Report
        - Create Markdown report: data-collection-report.md
        - Required data points:
          - Source(s) accessed
          - Number of user stories retrieved
          - Collection timestamp
          - Any issues or errors encountered
          - Success/failure statistics

      Step 6: Outputs
        - Output user-story-summary.md and data-collection-report.md in separate artifacts on canvas mode.

  - id: 2
    name: Generate Test Cases from User Stories
    description: Generate comprehensive test cases for each user story
    instructions: |
      Execute the workflow step by step (Steps 1-9).
      Strictly follow task steps; after each step, ask user to continue.

      Step 1: Acquire Knowledge
        - Read test-case-template.md file
        - Read test-case-guidelines.md file
        - Read test-case-checklist.md file
        - Keep this knowledge in memory for subsequent steps

      Step 2: Context Gathering (Optional)
        - Collect or read project documentation and reference materials:
          - Project name and code
          - General business context
          - Domain-specific terminology
          - Quality standards
          - Testing priorities

      Step 3: Input Verification
        - Check if current context has User Story Summary content
        - If not available, ask user to provide it

      Step 4: Generate Test Cases for Each User Story
        - Collect list of user stories
        - For each user story, extract:
          - User Story ID
          - User Story Title
          - Description/Narrative
          - Acceptance Criteria
          - Business Rules
          - Related User Stories
        - For each user story, generate test cases following test-case-template.md and test-case-guidelines.md
        - File naming: {{us-id}}.md (one file per user story)

      Step 5: Validation
        - Review generated test cases against test-case-checklist.md

      Step 6: User Review and Approval
        - Present test cases to user for review
        - Incorporate feedback as needed

      Step 7: Final Reporting
        - Generate testcase-generation-report.md with:
          - Project information
          - User stories processed
          - Total test cases created
          - Coverage statistics
          - Test case distribution by priority/type
          - Assumptions and notes
          - Recommendations

      Step 8: Generate Zephyr Export
        - Read zephyr-template.md template
        - Read zephyr-example.csv example file
        - Create zephyr.csv file following template format
        - For each generated test case file ({{us-id}}.md):
          - Convert test cases to Zephyr format
          - Append to zephyr.csv (test steps separated into multiple rows)
        - Validate CSV format before delivery

      Step 9: Generate Download Links
        - Create download links for:
          - All test case files ({{us-id}}.md)
          - testcase-generation-report.md
          - zephyr.csv

templates:
  - id: user-story-summary-template
    name: User Story Summary Template
    file: user-story-summary-template.md

  - id: test-case-template
    name: Test Case Template
    file: test-case-template.md

  - id: zephyr-template
    name: Zephyr Export Template
    file: zephyr-template.md

guidelines:
  - id: user-story-summary-guidelines
    name: User Story Summary Guidelines
    file: user-story-summary-guidelines.md

  - id: test-case-guidelines
    name: Test Case Generation Guidelines
    file: test-case-guidelines.md

checklists:
  - id: user-story-summary-checklist
    name: User Story Summary Checklist
    file: user-story-summary-checklist.md

  - id: test-case-checklist
    name: Test Case Checklist
    file: test-case-checklist.md

examples:
  - id: zephyr-example
    name: Zephyr CSV Example
    file: zephyr-example.csv
```

# User Story Summary Quality Checklist

## Document Information
- **Purpose**: Quality verification checklist for User Story Summary documents
- **Version**: 1.0
- **Last Updated**: 2025-10-22

---

## 1. Completeness Checks

### 1.1 Source Coverage
- [ ] All user stories from the source have been collected
- [ ] No user stories were skipped or missed during collection
- [ ] Failed collections are documented with reasons
- [ ] Source location and access method are documented

### 1.2 Content Completeness
- [ ] Each user story has a unique identifier (ID)
- [ ] Each user story has a clear title
- [ ] Each user story has a description/summary
- [ ] Each user story is assigned to at least one functional group
- [ ] Related user stories are identified and linked
- [ ] All mandatory fields from template are present

### 1.3 Documentation Sections
- [ ] Executive summary is present
- [ ] Table of contents is generated
- [ ] All functional groups are documented
- [ ] Statistics section is included (total stories, groups, etc.)
- [ ] Document metadata is present (date, version, source)

---

## 2. Format and Structure Compliance

### 2.1 Template Adherence
- [ ] Document follows the structure defined in `template.md`
- [ ] All required sections are present in correct order
- [ ] Section headers match template specifications
- [ ] Field formats match template requirements
- [ ] Optional sections are handled appropriately

### 2.2 Markdown Formatting
- [ ] Proper markdown syntax is used throughout
- [ ] Headers use correct hierarchy (H1, H2, H3, etc.)
- [ ] Lists are properly formatted (ordered/unordered)
- [ ] Links are properly formatted and functional
- [ ] Code blocks (if any) use proper syntax highlighting
- [ ] Tables (if any) are properly formatted

### 2.3 Readability
- [ ] Content is well-organized and easy to navigate
- [ ] Consistent terminology is used throughout
- [ ] No spelling or grammatical errors
- [ ] Appropriate use of whitespace and line breaks
- [ ] Clear and concise language

---

## 3. Grouping and Categorization

### 3.1 Functional Groups
- [ ] All functional groups are clearly defined
- [ ] Each group has a descriptive name
- [ ] Each group has a brief description/purpose
- [ ] Grouping criteria are consistent and logical
- [ ] No orphaned user stories (all assigned to groups)
- [ ] Group assignments make sense and are not arbitrary

### 3.2 Cross-Cutting Concerns
- [ ] User stories spanning multiple groups are identified
- [ ] Cross-cutting relationships are documented
- [ ] Shared dependencies are highlighted
- [ ] Common patterns are identified and noted

### 3.3 Group Organization
- [ ] Groups are arranged in logical order
- [ ] Related groups are positioned near each other
- [ ] Group hierarchy (if any) is clear
- [ ] Group boundaries are well-defined

---

## 4. Relationship Accuracy

### 4.1 Dependency Mapping
- [ ] All direct dependencies are identified
- [ ] Dependency types are clearly specified (blocks, blocked by, etc.)
- [ ] Bidirectional relationships are consistent
- [ ] Circular dependencies are identified and flagged
- [ ] Dependency chains are logical and traceable

### 4.2 Related Stories
- [ ] Related stories within same feature/epic are linked
- [ ] Prerequisite stories are identified
- [ ] Follow-up or extension stories are noted
- [ ] Relationship types are clearly labeled
- [ ] All cross-references are valid and bidirectional

### 4.3 Relationship Validation
- [ ] No broken or invalid references
- [ ] All referenced user story IDs exist
- [ ] Relationship logic is sound and makes sense
- [ ] No contradictory relationships

---

## 5. Data Integrity

### 5.1 User Story IDs
- [ ] All IDs are unique
- [ ] ID format is consistent
- [ ] IDs match source system format (if applicable)
- [ ] No duplicate IDs exist

### 5.2 Data Consistency
- [ ] User story titles match source data
- [ ] Descriptions accurately reflect source content
- [ ] No data corruption or garbled text
- [ ] Dates and timestamps are accurate
- [ ] Version information is correct

### 5.3 Source Traceability
- [ ] Each user story can be traced back to source
- [ ] Source references are provided (URLs, file paths, etc.)
- [ ] Collection metadata is accurate
- [ ] Audit trail is maintained

---

## 6. Summary Quality

### 6.1 Executive Summary
- [ ] Provides clear overview of the document
- [ ] Includes key statistics and metrics
- [ ] Highlights important findings or patterns
- [ ] Is concise yet comprehensive
- [ ] Suitable for stakeholder review

### 6.2 User Story Summaries
- [ ] Each summary is clear and concise
- [ ] Summaries capture key points without unnecessary detail
- [ ] Technical jargon is explained or avoided
- [ ] Summaries are consistent in style and depth
- [ ] Acceptance criteria (if included) are clear

### 6.3 Group Descriptions
- [ ] Each functional group has a clear description
- [ ] Group purpose and scope are well-defined
- [ ] Group relationships are explained
- [ ] Group-level insights are provided

---

## 7. Verification and Validation

### 7.1 Cross-Verification
- [ ] Sample of user stories manually verified against source
- [ ] Grouping logic verified with stakeholders (if required)
- [ ] Relationships validated through cross-checking
- [ ] Statistics calculated and verified

### 7.2 Quality Metrics
- [ ] Document completeness: ___% (target: 100%)
- [ ] Format compliance: ___% (target: 100%)
- [ ] Relationship accuracy: ___% (target: 95%+)
- [ ] Data integrity: ___% (target: 100%)

### 7.3 Known Issues
- [ ] All known issues are documented
- [ ] Workarounds or mitigations are noted
- [ ] Issue severity is assessed
- [ ] Resolution plan is documented (if applicable)

---

## 8. Deliverable Requirements

### 8.1 Required Files
- [ ] Main summary document: `user-story-summary.md`
- [ ] Data collection report: `data-collection-report.md`
- [ ] Data collection report (HTML): `data-collection-report.html`
- [ ] Verification report: `verification-report.md`

### 8.2 File Quality
- [ ] All files are properly named
- [ ] All files are in correct locations
- [ ] Files are properly formatted (MD/HTML)
- [ ] Files are complete and not corrupted
- [ ] Files can be opened and read without issues

### 8.3 Backup and Version Control
- [ ] Backup copies created
- [ ] Version information included in files
- [ ] Change history documented (if applicable)
- [ ] Previous versions archived (if applicable)

---

## 9. Stakeholder Requirements

### 9.1 Business Requirements
- [ ] Document meets stated business objectives
- [ ] All required information is present
- [ ] Document is suitable for intended audience
- [ ] Presentation format is appropriate

### 9.2 Technical Requirements
- [ ] Technical accuracy is verified
- [ ] Technical dependencies are correct
- [ ] Technical terminology is consistent
- [ ] Integration points are identified

### 9.3 Compliance Requirements
- [ ] Document follows organizational standards
- [ ] Naming conventions are followed
- [ ] Required approvals are obtained (if applicable)
- [ ] Confidentiality/security requirements are met

---

## 10. Final Review

### 10.1 Overall Quality
- [ ] Document is production-ready
- [ ] All critical issues are resolved
- [ ] Document meets quality standards
- [ ] Stakeholder feedback is incorporated

### 10.2 Approval Checklist
- [ ] Technical review completed
- [ ] Business review completed (if required)
- [ ] All checklist items are verified
- [ ] Document approved for distribution

### 10.3 Sign-off
- **Reviewer Name**: _________________
- **Review Date**: _________________
- **Status**: [ ] Approved [ ] Approved with conditions [ ] Rejected
- **Comments**: _________________

---

## Verification Results Summary

### Critical Issues (Must Fix)
- Count: ___
- List:

### Major Issues (Should Fix)
- Count: ___
- List:

### Minor Issues (Nice to Fix)
- Count: ___
- List:

### Overall Assessment
- [ ] **PASS** - Document meets all quality criteria
- [ ] **CONDITIONAL PASS** - Document acceptable with noted issues
- [ ] **FAIL** - Document requires significant rework

---

## Notes and Recommendations

### Strengths
-

### Areas for Improvement
-

### Recommendations for Next Version
-

---

**Checklist Version**: 1.0  
**Document Status**: Active  
**Next Review Date**: ___________

# User Story Template

Use this template to format each user story in the summary:

---

- **Story ID:** {{Story ID}}

- **Title:** {{Story Title}}

- **Preconditions:**
{{Preconditions}}

- **Description:**  
  As a **{{User Role}}**,  
  I want **{{what the user wants}}**  
  so that **{{why the user wants it}}**.

- **Acceptance Criteria:**  
  1. {{Acceptance Criterion 1}}  
  2. {{Acceptance Criterion 2}}  
  3. â€¦

- **Status:** {{To Do / In Progress / Done / â€¦}}

- **Related Stories:**  
  - {{Story ID / Title of related story}}  
  - â€¦  
  (If none, write "None")

- **Additional Notes (optional):**  
  - {{Any additional information or notes}}

---

